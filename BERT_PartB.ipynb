{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT PartB",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bf95478920794af98811e7bf9e6b471b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d437ce3c1d8742a691b468ac985c8764",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2d20078c76dd461ebc74c7cfcd130671",
              "IPY_MODEL_139c81a86f1f46f690f34b71d7130fc1"
            ]
          }
        },
        "d437ce3c1d8742a691b468ac985c8764": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2d20078c76dd461ebc74c7cfcd130671": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_726892e9eef34e1b9da54f1d19952ba6",
            "_dom_classes": [],
            "description": "  2%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 1044897,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 18854,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c30bbaacfa4a4050ab40b3dbc9d520bf"
          }
        },
        "139c81a86f1f46f690f34b71d7130fc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_217dc99e642b457991a9625365c407b5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 18854/1044897 [05:30&lt;4:38:43, 61.35it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_63d47ec572a54ccdbaf3df4ce9f27902"
          }
        },
        "726892e9eef34e1b9da54f1d19952ba6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c30bbaacfa4a4050ab40b3dbc9d520bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "217dc99e642b457991a9625365c407b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "63d47ec572a54ccdbaf3df4ce9f27902": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/orgoca/W207FinalProject/blob/BERT/BERT_PartB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDo9bwz8QArK"
      },
      "source": [
        "# Project 2 BERT Model B\n",
        "Quora Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NYPkw21y3Lz"
      },
      "source": [
        "# Load Data and Import Libraries\n",
        "\n",
        "First, we load all data and necessary libraries. We split the `train` data into `miniTrain` and `miniTest` dataframes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiJJo9swpVLu",
        "outputId": "654776d0-707f-4fd4-a017-d441bcf741f1"
      },
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n",
        "  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
        "  print('re-execute this cell.')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your runtime has 27.3 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyjvpQvqqNOf"
      },
      "source": [
        "#Import Libraries\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score, \\\n",
        "    recall_score, confusion_matrix, classification_report, \\\n",
        "    accuracy_score, f1_score, plot_confusion_matrix\n",
        "from sklearn_pandas import DataFrameMapper\n",
        "import csv\n",
        "import random"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S00Lid5Y9-rl",
        "outputId": "96f77caf-6d38-4061-936f-a9b7b0d9208a"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.9.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.1)\n",
            "Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (5.4.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bnFJA_9xJOF"
      },
      "source": [
        "# Code to read csv file from Google Drive into Colaboratory:\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNRE_EXJw_Qk"
      },
      "source": [
        "#Load test DF\n",
        "testLink = 'https://drive.google.com/file/d/1chKVOcXwNzGRe_hRxpGlq18NVaSRM8X9/view?usp=sharing'\n",
        "idTest = testLink.split('/')[-2]\n",
        "downloaded = drive.CreateFile({'id':idTest}) \n",
        "downloaded.GetContentFile('test.csv')  "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "iIF89_e_SjVy",
        "outputId": "d09d8a7d-a754-4a9c-b80f-0b13bc4e55be"
      },
      "source": [
        "test = pd.read_csv('test.csv')\n",
        "test"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>question_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000163e3ea7c7a74cd7</td>\n",
              "      <td>Why do so many women become so rude and arroga...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00002bd4fb5d505b9161</td>\n",
              "      <td>When should I apply for RV college of engineer...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00007756b4a147d2b0b3</td>\n",
              "      <td>What is it really like to be a nurse practitio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>000086e4b7e1c7146103</td>\n",
              "      <td>Who are entrepreneurs?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0000c4c3fbe8785a3090</td>\n",
              "      <td>Is education really making good people nowadays?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>375801</th>\n",
              "      <td>ffff7fa746bd6d6197a9</td>\n",
              "      <td>How many countries listed in gold import in in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>375802</th>\n",
              "      <td>ffffa1be31c43046ab6b</td>\n",
              "      <td>Is there an alternative to dresses on formal p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>375803</th>\n",
              "      <td>ffffae173b6ca6bfa563</td>\n",
              "      <td>Where I can find best friendship quotes in Tel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>375804</th>\n",
              "      <td>ffffb1f7f1a008620287</td>\n",
              "      <td>What are the causes of refraction of light?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>375805</th>\n",
              "      <td>fffff85473f4699474b0</td>\n",
              "      <td>Climate change is a worrying topic. How much t...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>375806 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                         qid                                      question_text\n",
              "0       0000163e3ea7c7a74cd7  Why do so many women become so rude and arroga...\n",
              "1       00002bd4fb5d505b9161  When should I apply for RV college of engineer...\n",
              "2       00007756b4a147d2b0b3  What is it really like to be a nurse practitio...\n",
              "3       000086e4b7e1c7146103                             Who are entrepreneurs?\n",
              "4       0000c4c3fbe8785a3090   Is education really making good people nowadays?\n",
              "...                      ...                                                ...\n",
              "375801  ffff7fa746bd6d6197a9  How many countries listed in gold import in in...\n",
              "375802  ffffa1be31c43046ab6b  Is there an alternative to dresses on formal p...\n",
              "375803  ffffae173b6ca6bfa563  Where I can find best friendship quotes in Tel...\n",
              "375804  ffffb1f7f1a008620287        What are the causes of refraction of light?\n",
              "375805  fffff85473f4699474b0  Climate change is a worrying topic. How much t...\n",
              "\n",
              "[375806 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cnl_313BvWqn"
      },
      "source": [
        "#Load train DF\n",
        "trainLink = 'https://drive.google.com/file/d/1fP-AWiUGLjLkL0c_u67HOUFmHOMO7qm2/view?usp=sharing'\n",
        "idTrain = trainLink.split('/')[-2]\n",
        "downloaded = drive.CreateFile({'id':idTrain}) \n",
        "downloaded.GetContentFile('train.csv')  "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0fZaycE0FBQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "outputId": "06b5e30f-5fc7-4bde-8f72-09ff956a9336"
      },
      "source": [
        "train = pd.read_csv('train.csv')\n",
        "train"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>question_text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00002165364db923c7e6</td>\n",
              "      <td>How did Quebec nationalists see their province...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000032939017120e6e44</td>\n",
              "      <td>Do you have an adopted dog, how would you enco...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0000412ca6e4628ce2cf</td>\n",
              "      <td>Why does velocity affect time? Does velocity a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>000042bf85aa498cd78e</td>\n",
              "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0000455dfa3e01eae3af</td>\n",
              "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1306117</th>\n",
              "      <td>ffffcc4e2331aaf1e41e</td>\n",
              "      <td>What other technical skills do you need as a c...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1306118</th>\n",
              "      <td>ffffd431801e5a2f4861</td>\n",
              "      <td>Does MS in ECE have good job prospects in USA ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1306119</th>\n",
              "      <td>ffffd48fb36b63db010c</td>\n",
              "      <td>Is foam insulation toxic?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1306120</th>\n",
              "      <td>ffffec519fa37cf60c78</td>\n",
              "      <td>How can one start a research project based on ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1306121</th>\n",
              "      <td>ffffed09fedb5088744a</td>\n",
              "      <td>Who wins in a battle between a Wolverine and a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1306122 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                          qid  ... target\n",
              "0        00002165364db923c7e6  ...      0\n",
              "1        000032939017120e6e44  ...      0\n",
              "2        0000412ca6e4628ce2cf  ...      0\n",
              "3        000042bf85aa498cd78e  ...      0\n",
              "4        0000455dfa3e01eae3af  ...      0\n",
              "...                       ...  ...    ...\n",
              "1306117  ffffcc4e2331aaf1e41e  ...      0\n",
              "1306118  ffffd431801e5a2f4861  ...      0\n",
              "1306119  ffffd48fb36b63db010c  ...      0\n",
              "1306120  ffffec519fa37cf60c78  ...      0\n",
              "1306121  ffffed09fedb5088744a  ...      0\n",
              "\n",
              "[1306122 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6zcj0EP2we6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81bdc229-dee9-4da8-bb61-3af12207297f"
      },
      "source": [
        "#Split Training Data into MiniTrain and MiniTest (Test data has no labels so impossible to measure error from it)\n",
        "# random.seed(10)\n",
        "# miniTrain, miniDev, miniTest = train_test_split(train, test_size=0.2)\n",
        "\n",
        "miniTrain, miniDev, miniTest = \\\n",
        "              np.split(train.sample(frac=1, random_state=42), \n",
        "                       [int(.8*len(train)), int(.9*len(train))])\n",
        "\n",
        "miniTrain.to_csv('miniTrain.csv', index=False)\n",
        "\n",
        "miniTest.to_csv('miniTest.csv', index=False)\n",
        "\n",
        "miniDev.to_csv('miniDev.csv', index = False)\n",
        "\n",
        "print(\"miniTrain: \",len(miniTrain), \"observations, \", round(len(miniTrain)/len(train)*100,0), \"%;\\n\" ,\n",
        "      \"miniDev: \",len(miniDev), \"observations, \", round(len(miniDev)/len(train)*100,0), \"%;\\n\" ,\n",
        "      \"miniTest: \",len(miniTest), \"observations, \", round(len(miniTest)/len(train)*100,0), \"%;\" )"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "miniTrain:  1044897 observations,  80.0 %;\n",
            " miniDev:  130612 observations,  10.0 %;\n",
            " miniTest:  130613 observations,  10.0 %;\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhK65MJrcaeF"
      },
      "source": [
        "#Even with a seed the randomization is messing up predictions since miniTest will not find the same questions further down, \n",
        "#so rather load a static version from a csv instead.\n",
        "\n",
        "miniTrain = pd.read_csv('miniTrain.csv')\n",
        "\n",
        "miniTest = pd.read_csv('miniTest.csv')\n",
        "\n",
        "miniDev = pd.read_csv('miniDev.csv')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "-PZERB97_U2A",
        "outputId": "9203b83f-aa76-436d-d377-47838fb4b741"
      },
      "source": [
        "miniTrain.drop(['qid'],axis=1,inplace=True)\n",
        "sentences=miniTrain.question_text.values\n",
        "labels = miniTrain.target.values\n",
        "miniTrain.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question_text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is the most effective classroom managemen...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Can I study abroad after 10th class from Bangl...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How can I make friends as a college junior?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>How do I download free APK Minecraft: Pocket E...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Like Kuvera, is \"Groww\" also a free online inv...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       question_text  target\n",
              "0  What is the most effective classroom managemen...       0\n",
              "1  Can I study abroad after 10th class from Bangl...       0\n",
              "2        How can I make friends as a college junior?       0\n",
              "3  How do I download free APK Minecraft: Pocket E...       0\n",
              "4  Like Kuvera, is \"Groww\" also a free online inv...       0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zVR0XMoSxyE",
        "outputId": "adc419df-30b0-47f7-b607-1863a2363dc5"
      },
      "source": [
        "pip install pytorch-pretrained-bert"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch-pretrained-bert in /usr/local/lib/python3.7/dist-packages (0.6.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.18.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (4.41.1)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.9.0+cu102)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.7.4.3)\n",
            "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-pretrained-bert) (0.5.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-pretrained-bert) (0.10.0)\n",
            "Requirement already satisfied: botocore<1.22.0,>=1.21.11 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-pretrained-bert) (1.21.11)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.22.0,>=1.21.11->boto3->pytorch-pretrained-bert) (2.8.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore<1.22.0,>=1.21.11->boto3->pytorch-pretrained-bert) (1.25.11)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.22.0,>=1.21.11->boto3->pytorch-pretrained-bert) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2021.5.30)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "IV3tlw-zWunp",
        "outputId": "0567e860-0a64-4a96-b2c7-234a4c8ad76a"
      },
      "source": [
        "miniTrain"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question_text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is the most effective classroom managemen...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Can I study abroad after 10th class from Bangl...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How can I make friends as a college junior?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>How do I download free APK Minecraft: Pocket E...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Like Kuvera, is \"Groww\" also a free online inv...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1044892</th>\n",
              "      <td>How is a video similar to ordinary graphics?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1044893</th>\n",
              "      <td>How does training with a speed bag make you a ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1044894</th>\n",
              "      <td>What marketing strategies are implemented to i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1044895</th>\n",
              "      <td>What are the characteristics of wireless adapt...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1044896</th>\n",
              "      <td>What is your experience with using fuel additi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1044897 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             question_text  target\n",
              "0        What is the most effective classroom managemen...       0\n",
              "1        Can I study abroad after 10th class from Bangl...       0\n",
              "2              How can I make friends as a college junior?       0\n",
              "3        How do I download free APK Minecraft: Pocket E...       0\n",
              "4        Like Kuvera, is \"Groww\" also a free online inv...       0\n",
              "...                                                    ...     ...\n",
              "1044892       How is a video similar to ordinary graphics?       0\n",
              "1044893  How does training with a speed bag make you a ...       0\n",
              "1044894  What marketing strategies are implemented to i...       0\n",
              "1044895  What are the characteristics of wireless adapt...       0\n",
              "1044896  What is your experience with using fuel additi...       0\n",
              "\n",
              "[1044897 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkIbE4pSXPw0"
      },
      "source": [
        "1) First we'll format our miniTrain and miniTest data into a specific TSV format that is friendly to the BERT pretrained model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "ho7dQZTvWHVe",
        "outputId": "f226284e-836f-4fc3-e38e-e7aac2626139"
      },
      "source": [
        "train_df_bert = pd.DataFrame({\n",
        "    'id':range(len(miniTrain)),\n",
        "    'label':miniTrain.target,\n",
        "    'alpha':['a']*miniTrain.shape[0],\n",
        "    'text': miniTrain.question_text.replace(r'\\n', ' ', regex=True)\n",
        "})\n",
        "\n",
        "train_df_bert.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>alpha</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>What is the most effective classroom managemen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>Can I study abroad after 10th class from Bangl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>How can I make friends as a college junior?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>How do I download free APK Minecraft: Pocket E...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>Like Kuvera, is \"Groww\" also a free online inv...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  label alpha                                               text\n",
              "0   0      0     a  What is the most effective classroom managemen...\n",
              "1   1      0     a  Can I study abroad after 10th class from Bangl...\n",
              "2   2      0     a        How can I make friends as a college junior?\n",
              "3   3      0     a  How do I download free APK Minecraft: Pocket E...\n",
              "4   4      0     a  Like Kuvera, is \"Groww\" also a free online inv..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "PM7xPnbEXAG5",
        "outputId": "779fb090-5d2d-49b5-a39d-5b493ef615f1"
      },
      "source": [
        "dev_df_bert = pd.DataFrame({\n",
        "    'id':range(len(miniTest)),\n",
        "    'label':miniTest.target,\n",
        "    'alpha':['a']*miniTest.shape[0],\n",
        "    'text': miniTest.question_text.replace(r'\\n', ' ', regex=True)\n",
        "})\n",
        "\n",
        "train_df_bert.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>alpha</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>What is the most effective classroom managemen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>Can I study abroad after 10th class from Bangl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>How can I make friends as a college junior?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>How do I download free APK Minecraft: Pocket E...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>Like Kuvera, is \"Groww\" also a free online inv...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  label alpha                                               text\n",
              "0   0      0     a  What is the most effective classroom managemen...\n",
              "1   1      0     a  Can I study abroad after 10th class from Bangl...\n",
              "2   2      0     a        How can I make friends as a college junior?\n",
              "3   3      0     a  How do I download free APK Minecraft: Pocket E...\n",
              "4   4      0     a  Like Kuvera, is \"Groww\" also a free online inv..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcLV0xd2XOgq"
      },
      "source": [
        "train_df_bert.to_csv('train.tsv', sep='\\t', index=False, header=False)\n",
        "\n",
        "dev_df_bert.to_csv('dev.tsv', sep='\\t', index=False, header=False)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9OOdWa6Yolv"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "import csv\n",
        "import os\n",
        "import sys\n",
        "import logging\n",
        "\n",
        "logger = logging.getLogger()\n",
        "csv.field_size_limit(2147483647) # Increase CSV reader's field limit incase we have long text.\n",
        "\n",
        "\n",
        "class InputExample(object):\n",
        "    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
        "\n",
        "    def __init__(self, guid, text_a, text_b=None, label=None):\n",
        "        \"\"\"Constructs a InputExample.\n",
        "        Args:\n",
        "            guid: Unique id for the example.\n",
        "            text_a: string. The untokenized text of the first sequence. For single\n",
        "            sequence tasks, only this sequence must be specified.\n",
        "            text_b: (Optional) string. The untokenized text of the second sequence.\n",
        "            Only must be specified for sequence pair tasks.\n",
        "            label: (Optional) string. The label of the example. This should be\n",
        "            specified for train and dev examples, but not for test examples.\n",
        "        \"\"\"\n",
        "        self.guid = guid\n",
        "        self.text_a = text_a\n",
        "        self.text_b = text_b\n",
        "        self.label = label\n",
        "\n",
        "\n",
        "class DataProcessor(object):\n",
        "    \"\"\"Base class for data converters for sequence classification data sets.\"\"\"\n",
        "\n",
        "    def get_train_examples(self, data_dir):\n",
        "        \"\"\"Gets a collection of `InputExample`s for the train set.\"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def get_dev_examples(self, data_dir):\n",
        "        \"\"\"Gets a collection of `InputExample`s for the dev set.\"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def get_labels(self):\n",
        "        \"\"\"Gets the list of labels for this data set.\"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    @classmethod\n",
        "    def _read_tsv(cls, input_file, quotechar=None):\n",
        "        \"\"\"Reads a tab separated value file.\"\"\"\n",
        "        with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
        "            reader = csv.reader(f, delimiter=\"\\t\", quotechar=quotechar)\n",
        "            lines = []\n",
        "            for line in reader:\n",
        "                if sys.version_info[0] == 2:\n",
        "                    line = list(unicode(cell, 'utf-8') for cell in line)\n",
        "                lines.append(line)\n",
        "            return lines\n",
        "\n",
        "\n",
        "class BinaryClassificationProcessor(DataProcessor):\n",
        "    \"\"\"Processor for binary classification dataset.\"\"\"\n",
        "\n",
        "    def get_train_examples(self, data_dir):\n",
        "        \"\"\"See base class.\"\"\"\n",
        "        return self._create_examples(\n",
        "            self._read_tsv(os.path.join(data_dir, \"train.tsv\")), \"train\")\n",
        "\n",
        "    def get_dev_examples(self, data_dir):\n",
        "        \"\"\"See base class.\"\"\"\n",
        "        return self._create_examples(\n",
        "            self._read_tsv(os.path.join(data_dir, \"dev.tsv\")), \"dev\")\n",
        "\n",
        "    def get_labels(self):\n",
        "        \"\"\"See base class.\"\"\"\n",
        "        return [\"0\", \"1\"]\n",
        "\n",
        "    def _create_examples(self, lines, set_type):\n",
        "        \"\"\"Creates examples for the training and dev sets.\"\"\"\n",
        "        examples = []\n",
        "        for (i, line) in enumerate(lines):\n",
        "            guid = \"%s-%s\" % (set_type, i)\n",
        "            text_a = line[3]\n",
        "            label = line[1]\n",
        "            examples.append(\n",
        "                InputExample(guid=guid, text_a=text_a, text_b=None, label=label))\n",
        "        return examples"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qWdqj2gY2KR"
      },
      "source": [
        "class InputFeatures(object):\n",
        "    \"\"\"A single set of features of data.\"\"\"\n",
        "\n",
        "    def __init__(self, input_ids, input_mask, segment_ids, label_id):\n",
        "        self.input_ids = input_ids\n",
        "        self.input_mask = input_mask\n",
        "        self.segment_ids = segment_ids\n",
        "        self.label_id = label_id\n",
        "\n",
        "\n",
        "def _truncate_seq_pair(tokens_a, tokens_b, max_length):\n",
        "    \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\n",
        "\n",
        "    # This is a simple heuristic which will always truncate the longer sequence\n",
        "    # one token at a time. This makes more sense than truncating an equal percent\n",
        "    # of tokens from each, since if one sequence is very short then each token\n",
        "    # that's truncated likely contains more information than a longer sequence.\n",
        "    while True:\n",
        "        total_length = len(tokens_a) + len(tokens_b)\n",
        "        if total_length <= max_length:\n",
        "            break\n",
        "        if len(tokens_a) > len(tokens_b):\n",
        "            tokens_a.pop()\n",
        "        else:\n",
        "            tokens_b.pop()\n",
        "\n",
        "\n",
        "def convert_example_to_feature(example_row):\n",
        "    # return example_row\n",
        "    example, label_map, max_seq_length, tokenizer, output_mode = example_row\n",
        "\n",
        "    tokens_a = tokenizer.tokenize(example.text_a)\n",
        "\n",
        "    tokens_b = None\n",
        "    if example.text_b:\n",
        "        tokens_b = tokenizer.tokenize(example.text_b)\n",
        "        # Modifies `tokens_a` and `tokens_b` in place so that the total\n",
        "        # length is less than the specified length.\n",
        "        # Account for [CLS], [SEP], [SEP] with \"- 3\"\n",
        "        _truncate_seq_pair(tokens_a, tokens_b, max_seq_length - 3)\n",
        "    else:\n",
        "        # Account for [CLS] and [SEP] with \"- 2\"\n",
        "        if len(tokens_a) > max_seq_length - 2:\n",
        "            tokens_a = tokens_a[:(max_seq_length - 2)]\n",
        "\n",
        "    tokens = [\"[CLS]\"] + tokens_a + [\"[SEP]\"]\n",
        "    segment_ids = [0] * len(tokens)\n",
        "\n",
        "    if tokens_b:\n",
        "        tokens += tokens_b + [\"[SEP]\"]\n",
        "        segment_ids += [1] * (len(tokens_b) + 1)\n",
        "\n",
        "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "    # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
        "    # tokens are attended to.\n",
        "    input_mask = [1] * len(input_ids)\n",
        "\n",
        "    # Zero-pad up to the sequence length.\n",
        "    padding = [0] * (max_seq_length - len(input_ids))\n",
        "    input_ids += padding\n",
        "    input_mask += padding\n",
        "    segment_ids += padding\n",
        "\n",
        "    assert len(input_ids) == max_seq_length\n",
        "    assert len(input_mask) == max_seq_length\n",
        "    assert len(segment_ids) == max_seq_length\n",
        "\n",
        "    if output_mode == \"classification\":\n",
        "        label_id = label_map[example.label]\n",
        "    elif output_mode == \"regression\":\n",
        "        label_id = float(example.label)\n",
        "    else:\n",
        "        raise KeyError(output_mode)\n",
        "\n",
        "    return InputFeatures(input_ids=input_ids,\n",
        "                         input_mask=input_mask,\n",
        "                         segment_ids=segment_ids,\n",
        "                         label_id=label_id)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSiF1_ltZc-j"
      },
      "source": [
        "TRAINING OUR BERT MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwPgNze5ZZgA"
      },
      "source": [
        "import torch\n",
        "import pickle\n",
        "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler, TensorDataset)\n",
        "from torch.nn import CrossEntropyLoss, MSELoss\n",
        "\n",
        "from tqdm import tqdm_notebook, trange\n",
        "import os\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM, BertForSequenceClassification\n",
        "from pytorch_pretrained_bert.optimization import BertAdam, WarmupLinearSchedule\n",
        "\n",
        "from multiprocessing import Pool, cpu_count\n",
        "from tools import *\n",
        "import convert_examples_to_features\n",
        "\n",
        "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
        "import logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTYu3vuDbAgB"
      },
      "source": [
        "# The input data dir. Should contain the .tsv files (or other data files) for the task.\n",
        "DATA_DIR = \"\"\n",
        "\n",
        "# Bert pre-trained model selected in the list: bert-base-uncased, \n",
        "# bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased,\n",
        "# bert-base-multilingual-cased, bert-base-chinese.\n",
        "BERT_MODEL = 'bert-base-cased'\n",
        "\n",
        "# The name of the task to train.I'm going to name this 'Quora'.\n",
        "TASK_NAME = 'Quora'\n",
        "\n",
        "# The output directory where the fine-tuned model and checkpoints will be written.\n",
        "OUTPUT_DIR = f'outputs/{TASK_NAME}/'\n",
        "\n",
        "# The directory where the evaluation reports will be written to.\n",
        "REPORTS_DIR = f'reports/{TASK_NAME}_evaluation_report/'\n",
        "\n",
        "# This is where BERT will look for pre-trained models to load parameters from.\n",
        "CACHE_DIR = 'cache/'\n",
        "\n",
        "# The maximum total input sequence length after WordPiece tokenization.\n",
        "# Sequences longer than this will be truncated, and sequences shorter than this will be padded.\n",
        "MAX_SEQ_LENGTH = 128\n",
        "\n",
        "TRAIN_BATCH_SIZE = 24\n",
        "EVAL_BATCH_SIZE = 32\n",
        "LEARNING_RATE = 2e-5\n",
        "NUM_TRAIN_EPOCHS = 1\n",
        "RANDOM_SEED = 42\n",
        "GRADIENT_ACCUMULATION_STEPS = 1\n",
        "WARMUP_PROPORTION = 0.1\n",
        "OUTPUT_MODE = 'classification'\n",
        "\n",
        "CONFIG_NAME = \"config.json\"\n",
        "WEIGHTS_NAME = \"pytorch_model.bin\""
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZ8Yj93nbPOD"
      },
      "source": [
        "output_mode = OUTPUT_MODE\n",
        "\n",
        "cache_dir = CACHE_DIR"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEWxFxs9bRTn"
      },
      "source": [
        "if os.path.exists(REPORTS_DIR) and os.listdir(REPORTS_DIR):\n",
        "        REPORTS_DIR += f'/report_{len(os.listdir(REPORTS_DIR))}'\n",
        "        os.makedirs(REPORTS_DIR)\n",
        "if not os.path.exists(REPORTS_DIR):\n",
        "    os.makedirs(REPORTS_DIR)\n",
        "    REPORTS_DIR += f'/report_{len(os.listdir(REPORTS_DIR))}'\n",
        "    os.makedirs(REPORTS_DIR)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_R12gKDbbU97"
      },
      "source": [
        "if os.path.exists(OUTPUT_DIR) and os.listdir(OUTPUT_DIR):\n",
        "        raise ValueError(\"Output directory ({}) already exists and is not empty.\".format(OUTPUT_DIR))\n",
        "if not os.path.exists(OUTPUT_DIR):\n",
        "    os.makedirs(OUTPUT_DIR)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_T2W2dJbX2r"
      },
      "source": [
        "processor = BinaryClassificationProcessor()\n",
        "train_examples = processor.get_train_examples(DATA_DIR)\n",
        "train_examples_len = len(train_examples)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spVFao4EbdfC"
      },
      "source": [
        "label_list = processor.get_labels() # [0, 1] for binary classification\n",
        "num_labels = len(label_list)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwSp1c0dbgzE"
      },
      "source": [
        "num_train_optimization_steps = int(\n",
        "    train_examples_len / TRAIN_BATCH_SIZE / GRADIENT_ACCUMULATION_STEPS) * NUM_TRAIN_EPOCHS"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5Cx8JzCbl10",
        "outputId": "7cd9dd4f-ddc7-450d-b6f9-39cfeba7d6e7"
      },
      "source": [
        "# Load pre-trained model tokenizer (vocabulary)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased', do_lower_case=False)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:pytorch_pretrained_bert.tokenization:loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /root/.pytorch_pretrained_bert/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSf4DA3xboTF"
      },
      "source": [
        "label_map = {label: i for i, label in enumerate(label_list)}\n",
        "train_examples_for_processing = [(example, label_map, MAX_SEQ_LENGTH, tokenizer, OUTPUT_MODE) for example in train_examples]"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "bf95478920794af98811e7bf9e6b471b",
            "d437ce3c1d8742a691b468ac985c8764",
            "2d20078c76dd461ebc74c7cfcd130671",
            "139c81a86f1f46f690f34b71d7130fc1",
            "726892e9eef34e1b9da54f1d19952ba6",
            "c30bbaacfa4a4050ab40b3dbc9d520bf",
            "217dc99e642b457991a9625365c407b5",
            "63d47ec572a54ccdbaf3df4ce9f27902"
          ]
        },
        "id": "WOJRmSHibszD",
        "outputId": "6d7ee826-3e05-498b-8d05-ed229f5def44"
      },
      "source": [
        "process_count = cpu_count() - 1\n",
        "if __name__ ==  '__main__':\n",
        "    print(f'Preparing to convert {train_examples_len} examples..')\n",
        "    print(f'Spawning {process_count} processes..')\n",
        "    with Pool(process_count) as p:\n",
        "        train_features = list(tqdm_notebook(p.imap(convert_examples_to_features.convert_example_to_feature, train_examples_for_processing), total=train_examples_len))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preparing to convert 1044897 examples..\n",
            "Spawning 3 processes..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bf95478920794af98811e7bf9e6b471b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1044897.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Process ForkPoolWorker-1:\n",
            "Process ForkPoolWorker-2:\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
            "    task = get()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
            "    task = get()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 352, in get\n",
            "    res = self._reader.recv_bytes()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
            "    with self._rlock:\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 216, in recv_bytes\n",
            "    buf = self._recv_bytes(maxlength)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
            "    buf = self._recv(4)\n",
            "KeyboardInterrupt\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
            "    chunk = read(handle, remaining)\n",
            "Process ForkPoolWorker-3:\n",
            "KeyboardInterrupt\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
            "    task = get()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 354, in get\n",
            "    return _ForkingPickler.loads(res)\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m                 \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    734\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-2dd9a213f4ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Spawning {process_count} processes..'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_count\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mtrain_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert_examples_to_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_example_to_feature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_examples_for_processing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_examples_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m             \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    735\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    738\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m                     \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfOKPAiorrD1"
      },
      "source": [
        "with open(DATA_DIR + \"train_features.pkl\", \"wb\") as f:\n",
        "    pickle.dump(train_features, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lsj9C1qib93e"
      },
      "source": [
        "FINE TUNING OUR MODEL\n",
        "\n",
        "If you don't want to retrain the whole model, start from here. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfWBd0upb_-d"
      },
      "source": [
        "# Load pre-trained model (weights)\n",
        "# model = BertForSequenceClassification.from_pretrained(BERT_MODEL, cache_dir=CACHE_DIR, num_labels=num_labels)\n",
        "model = BertForSequenceClassification.from_pretrained(CACHE_DIR + 'bert-base-cased.tar.gz', cache_dir=CACHE_DIR, num_labels=num_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H55AXJN0cUXS"
      },
      "source": [
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vg-7R8tWcUfv"
      },
      "source": [
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "    ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSLR7cxFcepQ"
      },
      "source": [
        "optimizer = BertAdam(optimizer_grouped_parameters,\n",
        "                     lr=LEARNING_RATE,\n",
        "                     warmup=WARMUP_PROPORTION,\n",
        "                     t_total=num_train_optimization_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVPkNCTnchyt"
      },
      "source": [
        "global_step = 0\n",
        "nb_tr_steps = 0\n",
        "tr_loss = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7FAf8PCcj5u"
      },
      "source": [
        "logger.info(\"***** Running training *****\")\n",
        "logger.info(\"  Num examples = %d\", train_examples_len)\n",
        "logger.info(\"  Batch size = %d\", TRAIN_BATCH_SIZE)\n",
        "logger.info(\"  Num steps = %d\", num_train_optimization_steps)\n",
        "all_input_ids = torch.tensor([f.input_ids for f in train_features], dtype=torch.long)\n",
        "all_input_mask = torch.tensor([f.input_mask for f in train_features], dtype=torch.long)\n",
        "all_segment_ids = torch.tensor([f.segment_ids for f in train_features], dtype=torch.long)\n",
        "\n",
        "if OUTPUT_MODE == \"classification\":\n",
        "    all_label_ids = torch.tensor([f.label_id for f in train_features], dtype=torch.long)\n",
        "elif OUTPUT_MODE == \"regression\":\n",
        "    all_label_ids = torch.tensor([f.label_id for f in train_features], dtype=torch.float)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0S9Bk0Ocn9J"
      },
      "source": [
        "train_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=TRAIN_BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyZyumR-csJE"
      },
      "source": [
        "TRAINING TIME"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_SBMDTlcrIB"
      },
      "source": [
        "model.train()\n",
        "for _ in trange(int(NUM_TRAIN_EPOCHS), desc=\"Epoch\"):\n",
        "    tr_loss = 0\n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        "    for step, batch in enumerate(tqdm_notebook(train_dataloader, desc=\"Iteration\")):\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        input_ids, input_mask, segment_ids, label_ids = batch\n",
        "\n",
        "        logits = model(input_ids, segment_ids, input_mask, labels=None)\n",
        "\n",
        "        if OUTPUT_MODE == \"classification\":\n",
        "            loss_fct = CrossEntropyLoss()\n",
        "            loss = loss_fct(logits.view(-1, num_labels), label_ids.view(-1))\n",
        "        elif OUTPUT_MODE == \"regression\":\n",
        "            loss_fct = MSELoss()\n",
        "            loss = loss_fct(logits.view(-1), label_ids.view(-1))\n",
        "\n",
        "        if GRADIENT_ACCUMULATION_STEPS > 1:\n",
        "            loss = loss / GRADIENT_ACCUMULATION_STEPS\n",
        "\n",
        "        loss.backward()\n",
        "        print(\"\\r%f\" % loss, end='')\n",
        "        \n",
        "        tr_loss += loss.item()\n",
        "        nb_tr_examples += input_ids.size(0)\n",
        "        nb_tr_steps += 1\n",
        "        if (step + 1) % GRADIENT_ACCUMULATION_STEPS == 0:\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            global_step += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-HGJyYfczDV"
      },
      "source": [
        "model_to_save = model.module if hasattr(model, 'module') else model  # Only save the model it-self\n",
        "\n",
        "# If we save using the predefined names, we can load using `from_pretrained`\n",
        "output_model_file = os.path.join(OUTPUT_DIR, WEIGHTS_NAME)\n",
        "output_config_file = os.path.join(OUTPUT_DIR, CONFIG_NAME)\n",
        "\n",
        "torch.save(model_to_save.state_dict(), output_model_file)\n",
        "model_to_save.config.to_json_file(output_config_file)\n",
        "tokenizer.save_vocabulary(OUTPUT_DIR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWlEQhawH2PP"
      },
      "source": [
        "MODEL EVALUATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "up-YtQ9IH360"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "from sklearn.metrics import matthews_corrcoef, confusion_matrix\n",
        "\n",
        "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler,\n",
        "                              TensorDataset)\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "from torch.nn import CrossEntropyLoss, MSELoss\n",
        "\n",
        "from tools import *\n",
        "from multiprocessing import Pool, cpu_count\n",
        "import convert_examples_to_features\n",
        "\n",
        "from tqdm import tqdm_notebook, trange\n",
        "import os\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM, BertForSequenceClassification\n",
        "from pytorch_pretrained_bert.optimization import BertAdam, WarmupLinearSchedule\n",
        "\n",
        "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
        "import logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeS8MYjgH-Ba"
      },
      "source": [
        "# The input data dir. Should contain the .tsv files (or other data files) for the task.\n",
        "DATA_DIR = \"data/\"\n",
        "\n",
        "# Bert pre-trained model selected in the list: bert-base-uncased, \n",
        "# bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased,\n",
        "# bert-base-multilingual-cased, bert-base-chinese.\n",
        "BERT_MODEL = 'Quora.tar.gz'\n",
        "\n",
        "# The name of the task to train.I'm going to name this 'Quora'.\n",
        "TASK_NAME = 'Quora'\n",
        "\n",
        "# The output directory where the fine-tuned model and checkpoints will be written.\n",
        "OUTPUT_DIR = f'outputs/{TASK_NAME}/'\n",
        "\n",
        "# The directory where the evaluation reports will be written to.\n",
        "REPORTS_DIR = f'reports/{TASK_NAME}_evaluation_reports/'\n",
        "\n",
        "# This is where BERT will look for pre-trained models to load parameters from.\n",
        "CACHE_DIR = 'cache/'\n",
        "\n",
        "# The maximum total input sequence length after WordPiece tokenization.\n",
        "# Sequences longer than this will be truncated, and sequences shorter than this will be padded.\n",
        "MAX_SEQ_LENGTH = 128\n",
        "\n",
        "TRAIN_BATCH_SIZE = 24\n",
        "EVAL_BATCH_SIZE = 8\n",
        "LEARNING_RATE = 2e-5\n",
        "NUM_TRAIN_EPOCHS = 1\n",
        "RANDOM_SEED = 42\n",
        "GRADIENT_ACCUMULATION_STEPS = 1\n",
        "WARMUP_PROPORTION = 0.1\n",
        "OUTPUT_MODE = 'classification'\n",
        "\n",
        "CONFIG_NAME = \"config.json\"\n",
        "WEIGHTS_NAME = \"pytorch_model.bin\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jxch3LMOIGZA"
      },
      "source": [
        "if os.path.exists(REPORTS_DIR) and os.listdir(REPORTS_DIR):\n",
        "        REPORTS_DIR += f'/report_{len(os.listdir(REPORTS_DIR))}'\n",
        "        os.makedirs(REPORTS_DIR)\n",
        "if not os.path.exists(REPORTS_DIR):\n",
        "    os.makedirs(REPORTS_DIR)\n",
        "    REPORTS_DIR += f'/report_{len(os.listdir(REPORTS_DIR))}'\n",
        "    os.makedirs(REPORTS_DIR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnm0JG__IJeO"
      },
      "source": [
        "def get_eval_report(task_name, labels, preds):\n",
        "    mcc = matthews_corrcoef(labels, preds)\n",
        "    tn, fp, fn, tp = confusion_matrix(labels, preds).ravel()\n",
        "    return {\n",
        "        \"task\": task_name,\n",
        "        \"mcc\": mcc,\n",
        "        \"tp\": tp,\n",
        "        \"tn\": tn,\n",
        "        \"fp\": fp,\n",
        "        \"fn\": fn,\n",
        "        \"f1\": f1_score\n",
        "    }\n",
        "\n",
        "def compute_metrics(task_name, labels, preds):\n",
        "    assert len(preds) == len(labels)\n",
        "    return get_eval_report(task_name, labels, preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrrYKBLAISOH"
      },
      "source": [
        "# Load pre-trained model tokenizer (vocabulary)\n",
        "tokenizer = BertTokenizer.from_pretrained(OUTPUT_DIR + 'vocab.txt', do_lower_case=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wi3xnBI0Iq3D"
      },
      "source": [
        "processor = BinaryClassificationProcessor()\n",
        "eval_examples = processor.get_dev_examples(DATA_DIR)\n",
        "label_list = processor.get_labels() # [0, 1] for binary classification\n",
        "num_labels = len(label_list)\n",
        "eval_examples_len = len(eval_examples)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LK2v35iVJE2T"
      },
      "source": [
        "label_map = {label: i for i, label in enumerate(label_list)}\n",
        "eval_examples_for_processing = [(example, label_map, MAX_SEQ_LENGTH, tokenizer, OUTPUT_MODE) for example in eval_examples]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WXlwLVvJINT"
      },
      "source": [
        "process_count = cpu_count() - 1\n",
        "if __name__ ==  '__main__':\n",
        "    print(f'Preparing to convert {eval_examples_len} examples..')\n",
        "    print(f'Spawning {process_count} processes..')\n",
        "    with Pool(process_count) as p:\n",
        "        eval_features = list(tqdm_notebook(p.imap(convert_examples_to_features.convert_example_to_feature, eval_examples_for_processing), total=eval_examples_len))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLwy64smJwnY"
      },
      "source": [
        "all_input_ids = torch.tensor([f.input_ids for f in eval_features], dtype=torch.long)\n",
        "all_input_mask = torch.tensor([f.input_mask for f in eval_features], dtype=torch.long)\n",
        "all_segment_ids = torch.tensor([f.segment_ids for f in eval_features], dtype=torch.long)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsW6vzojJzK5"
      },
      "source": [
        "if OUTPUT_MODE == \"classification\":\n",
        "    all_label_ids = torch.tensor([f.label_id for f in eval_features], dtype=torch.long)\n",
        "elif OUTPUT_MODE == \"regression\":\n",
        "    all_label_ids = torch.tensor([f.label_id for f in eval_features], dtype=torch.float)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dVWVSC-J1pQ"
      },
      "source": [
        "eval_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
        "\n",
        "# Run prediction for full data\n",
        "eval_sampler = SequentialSampler(eval_data)\n",
        "eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=EVAL_BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kmHILF_J36p"
      },
      "source": [
        "# Load pre-trained model (weights)\n",
        "model = BertForSequenceClassification.from_pretrained(CACHE_DIR + BERT_MODEL, cache_dir=CACHE_DIR, num_labels=len(label_list))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uM3eQRrDJ8b9"
      },
      "source": [
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfaNXYptJ-mT"
      },
      "source": [
        "model.eval()\n",
        "eval_loss = 0\n",
        "nb_eval_steps = 0\n",
        "preds = []\n",
        "\n",
        "for input_ids, input_mask, segment_ids, label_ids in tqdm_notebook(eval_dataloader, desc=\"Evaluating\"):\n",
        "    input_ids = input_ids.to(device)\n",
        "    input_mask = input_mask.to(device)\n",
        "    segment_ids = segment_ids.to(device)\n",
        "    label_ids = label_ids.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = model(input_ids, segment_ids, input_mask, labels=None)\n",
        "\n",
        "    # create eval loss and other metric required by the task\n",
        "    if OUTPUT_MODE == \"classification\":\n",
        "        loss_fct = CrossEntropyLoss()\n",
        "        tmp_eval_loss = loss_fct(logits.view(-1, num_labels), label_ids.view(-1))\n",
        "    elif OUTPUT_MODE == \"regression\":\n",
        "        loss_fct = MSELoss()\n",
        "        tmp_eval_loss = loss_fct(logits.view(-1), label_ids.view(-1))\n",
        "\n",
        "    eval_loss += tmp_eval_loss.mean().item()\n",
        "    nb_eval_steps += 1\n",
        "    if len(preds) == 0:\n",
        "        preds.append(logits.detach().cpu().numpy())\n",
        "    else:\n",
        "        preds[0] = np.append(\n",
        "            preds[0], logits.detach().cpu().numpy(), axis=0)\n",
        "\n",
        "eval_loss = eval_loss / nb_eval_steps\n",
        "preds = preds[0]\n",
        "if OUTPUT_MODE == \"classification\":\n",
        "    preds = np.argmax(preds, axis=1)\n",
        "elif OUTPUT_MODE == \"regression\":\n",
        "    preds = np.squeeze(preds)\n",
        "result = compute_metrics(TASK_NAME, all_label_ids.numpy(), preds)\n",
        "\n",
        "result['eval_loss'] = eval_loss\n",
        "\n",
        "output_eval_file = os.path.join(REPORTS_DIR, \"eval_results.txt\")\n",
        "with open(output_eval_file, \"w\") as writer:\n",
        "    logger.info(\"***** Eval results *****\")\n",
        "    for key in (result.keys()):\n",
        "        logger.info(\"  %s = %s\", key, str(result[key]))\n",
        "        writer.write(\"%s = %s\\n\" % (key, str(result[key])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dk5A3vtUKEkI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}