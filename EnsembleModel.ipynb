{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import precision_score, \\\n",
    "    recall_score, confusion_matrix, classification_report, \\\n",
    "    accuracy_score, f1_score, plot_confusion_matrix\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import fasttext\n",
    "import joblib\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>alpha</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>What is the most effective classroom managemen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>Can I study abroad after 10th class from Bangl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>How can I make friends as a college junior?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>How do I download free APK Minecraft: Pocket E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>Like Kuvera, is \"Groww\" also a free online inv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044892</th>\n",
       "      <td>1044892</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>How is a video similar to ordinary graphics?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044893</th>\n",
       "      <td>1044893</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>How does training with a speed bag make you a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044894</th>\n",
       "      <td>1044894</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>What marketing strategies are implemented to i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044895</th>\n",
       "      <td>1044895</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>What are the characteristics of wireless adapt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044896</th>\n",
       "      <td>1044896</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>What is your experience with using fuel additi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1044897 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  label alpha  \\\n",
       "0              0      0     a   \n",
       "1              1      0     a   \n",
       "2              2      0     a   \n",
       "3              3      0     a   \n",
       "4              4      0     a   \n",
       "...          ...    ...   ...   \n",
       "1044892  1044892      0     a   \n",
       "1044893  1044893      0     a   \n",
       "1044894  1044894      0     a   \n",
       "1044895  1044895      0     a   \n",
       "1044896  1044896      0     a   \n",
       "\n",
       "                                                      text  \n",
       "0        What is the most effective classroom managemen...  \n",
       "1        Can I study abroad after 10th class from Bangl...  \n",
       "2              How can I make friends as a college junior?  \n",
       "3        How do I download free APK Minecraft: Pocket E...  \n",
       "4        Like Kuvera, is \"Groww\" also a free online inv...  \n",
       "...                                                    ...  \n",
       "1044892       How is a video similar to ordinary graphics?  \n",
       "1044893  How does training with a speed bag make you a ...  \n",
       "1044894  What marketing strategies are implemented to i...  \n",
       "1044895  What are the characteristics of wireless adapt...  \n",
       "1044896  What is your experience with using fuel additi...  \n",
       "\n",
       "[1044897 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = [\n",
    "    \"id\",\n",
    "    \"label\",\n",
    "    \"alpha\",\n",
    "    \"text\"\n",
    "]\n",
    "\n",
    "train = pd.read_csv('/Users/julian.hicks/Documents/mids/w207ml/W207FinalProject/datasets/train.tsv', names=columns, sep=\"\\t\")\n",
    "test = pd.read_csv('/Users/julian.hicks/Documents/mids/w207ml/W207FinalProject/datasets/test.tsv', names=columns, sep=\"\\t\")\n",
    "dev = pd.read_csv('/Users/julian.hicks/Documents/mids/w207ml/W207FinalProject/datasets/dev.tsv', names=columns, sep=\"\\t\")\n",
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up `TextObject`s and Transform as Appropriate for Each Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk as nltk\n",
    "import re\n",
    "import gensim \n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "\n",
    "class TextObject(pd.DataFrame):\n",
    "    \"\"\"\n",
    "    A collection of strings for processing. Is a DataFrame with specific \n",
    "    columns. \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__(columns=[\n",
    "            \"original_text\",\n",
    "            \"text\",\n",
    "            \"label\"\n",
    "        ]\n",
    "        )\n",
    "        self._attrs[\"applied_transformations\"] = []\n",
    "        nltk.download(\"stopwords\")\n",
    "        nltk.download(\"punkt\")\n",
    "\n",
    "    def add_text(self, text_collection, labels=None):\n",
    "        \"\"\"\n",
    "        Adds a collection of text to to the TextObject. Accepts an iterable or \n",
    "        array-like of all text strings. Optionally, accepts labels of the same \n",
    "        length. Modifies self to be a pandas DataFrame with column \"text\" and \n",
    "        potentially \"labels\".\n",
    "        \"\"\"\n",
    "        self[\"original_text\"] = text_collection\n",
    "        self[\"text\"] = self.original_text\n",
    "        self._attrs[\"applied_transformations\"] = []\n",
    "        if type(labels) == type(None):\n",
    "            return\n",
    "        if len(labels) == len(self):\n",
    "            self[\"label\"] = labels\n",
    "\n",
    "    # Text Processing Methods:\n",
    "\n",
    "    def text_processing(self, function):\n",
    "        \"\"\"\n",
    "        Applies a generic text processing function to the self.text field.\n",
    "        \"\"\"\n",
    "        self.text = self.text.apply(function)\n",
    "        self._attrs[\"applied_transformations\"].append(function.__name__)\n",
    "\n",
    "    def lower(self):\n",
    "        self.text = self.text.str.lower()\n",
    "        self._attrs[\"applied_transformations\"].append(\"lower\")\n",
    "    \n",
    "    def strip(self):\n",
    "        self.text = self.text.str.strip()\n",
    "        self._attrs[\"applied_transformations\"].append(\"strip\")\n",
    "\n",
    "    def remove_single_digits(self):\n",
    "        self.text = self.text.apply(lambda text: re.sub(\"([\\d]+)\", \"\", text))\n",
    "        self._attrs[\"applied_transformations\"].append(\"remove_single_digits\")\n",
    "    \n",
    "    def remove_nonletter_chars(self):\n",
    "        self.text = self.text.apply(lambda text: re.sub(\"[^A-Za-z0-9 \\\\n]\", \" \", text))\n",
    "        self._attrs[\"applied_transformations\"].append(\"remove_nonletter_chars\")\n",
    "\n",
    "    def stop_word_tokenize(self):\n",
    "        def tokenize(text):\n",
    "            self.stoplist = nltk.corpus.stopwords.words('english')\n",
    "            finalTokens = []\n",
    "            tokens = nltk.word_tokenize(text)\n",
    "            for w in tokens:\n",
    "                if (w not in self.stoplist):\n",
    "                    finalTokens.append(w)\n",
    "            text = \" \".join(finalTokens)\n",
    "            return text\n",
    "        self.text = self.text.apply(tokenize)\n",
    "        self._attrs[\"applied_transformations\"].append(\"stop_word_tokenize\")\n",
    "    \n",
    "    def stem_sentence(self):\n",
    "        def stem(text):\n",
    "            porter=PorterStemmer()\n",
    "            token_words=nltk.tokenize.word_tokenize(text)\n",
    "            token_words\n",
    "            stem_sentence=[]\n",
    "            for word in token_words:\n",
    "                stem_sentence.append(porter.stem(word))\n",
    "                stem_sentence.append(\" \")\n",
    "            return \"\".join(stem_sentence)\n",
    "        self.text = self.text.apply(stem)\n",
    "        self._attrs[\"applied_transformations\"].append(\"stem_sentence\")\n",
    "\n",
    "    def lemmatize_sentence(self):\n",
    "        def lem(text):\n",
    "            wordnet_lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "            #token_words\n",
    "            token_words=nltk.tokenize.word_tokenize(text)\n",
    "            lemm_sentence=[]\n",
    "            for word in token_words:\n",
    "                lemm_sentence.append(wordnet_lemmatizer.lemmatize(word))\n",
    "                lemm_sentence.append(\" \")\n",
    "            return \"\".join(lemm_sentence)\n",
    "        self.text = self.text.apply(lem)\n",
    "        self._attrs[\"applied_transformations\"].append(\"lemmatize_sentence\")\n",
    "\n",
    "    def process_all(self, lower=True, strip=True, remove_single_digits =True, \n",
    "        remove_nonletter_chars=True, stop_word_tokenize=True, stem_sentence=True,\n",
    "        lemmatize_sentence=True):\n",
    "        if lower:\n",
    "            self.lower()\n",
    "        if strip:\n",
    "            self.strip()\n",
    "        if remove_single_digits:\n",
    "            self.remove_single_digits()\n",
    "        if remove_nonletter_chars:\n",
    "            self.remove_nonletter_chars()\n",
    "        if stop_word_tokenize:\n",
    "            self.stop_word_tokenize()\n",
    "        if stem_sentence:\n",
    "            self.stem_sentence()\n",
    "        if lemmatize_sentence:\n",
    "            self.lemmatize_sentence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/julian.hicks/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/julian.hicks/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/julian.hicks/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/julian.hicks/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/julian.hicks/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/julian.hicks/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "def createTextObject(df):\n",
    "    out = TextObject()\n",
    "    out.add_text(df.text, df.label)\n",
    "    return out\n",
    "\n",
    "train = createTextObject(train)\n",
    "test = createTextObject(test)\n",
    "dev = createTextObject(dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logit Model \n",
    "This model uses a CountVectorizer and no text transformations. Since we've saved down the model using joblib, we can just load it here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, max_iter=1000)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model = joblib.load(\"lrmodel.joblib\")\n",
    "lr_thresh = joblib.load(\"lr_ot.joblib\")\n",
    "lr_vect = joblib.load(\"lr_cv.joblib\")\n",
    "lr_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_train = lr_vect.transform(train.text)\n",
    "lr_test = lr_vect.transform(test.text)\n",
    "lr_dev = lr_vect.transform(dev.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient-Boosted Tree\n",
    "This model uses a TF-IDF Vectorizer and a number of transformations: `.lower()`, `.strip()`, `.remove_single_digits()`, `.remove_nonletter_chars()` & `.stop_word_tokenize()`\n",
    "We will load the model, and vectorizer and set up the right transformed `TextObject`s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_model = joblib.load(\"gbmodel.joblib\")\n",
    "gb_thresh = joblib.load(\"gb_ot.joblib\")\n",
    "gb_vect = joblib.load(\"gb_tv.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/julian.hicks/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/julian.hicks/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/julian.hicks/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/julian.hicks/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/julian.hicks/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/julian.hicks/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.TextObject'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-7fe0180fad7b>:69: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  self.stoplist = nltk.corpus.stopwords.words('english')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gb_train = createTextObject(train)\n",
    "gb_test  = createTextObject(test)\n",
    "gb_dev   = createTextObject(dev)\n",
    "\n",
    "print(type(gb_train))\n",
    "\n",
    "gb_train.lower()\n",
    "gb_train.strip()\n",
    "gb_train.remove_single_digits()\n",
    "gb_train.remove_nonletter_chars()\n",
    "gb_train.stop_word_tokenize()\n",
    "\n",
    "for m in gb_train._attrs[\"applied_transformations\"]:\n",
    "    getattr(gb_dev, m)()\n",
    "    getattr(gb_test, m)()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_train_v = gb_vect.transform(gb_train.text)\n",
    "gb_test_v  = gb_vect.transform(gb_test.text)\n",
    "gb_dev_v   = gb_vect.transform(gb_dev.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes\n",
    "\n",
    "We also build a Naive Bayes model, which had similar transformations to our Gradient-Boosted Classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model = joblib.load(\"nb_model.joblib\")\n",
    "nb_vect = joblib.load(\"nb_cv.joblib\")\n",
    "nb_thresh = joblib.load(\"nb_ot.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_train = nb_vect.transform(gb_train.text)\n",
    "nb_test  = nb_vect.transform(gb_test.text)\n",
    "nb_dev   = nb_vect.transform(gb_dev.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FastText \n",
    "FastText is a pre-trained model meant to help with lightweight text-classification. We attempted both a transformed and untransformed methodology with this model, and got better results with the untransformed model. We will use that version, and therefore no major changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "ft_model = fasttext.load_model(\"ft_model_orig.bin\")\n",
    "ft_thresh = joblib.load(\"ft_ot.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to munge the outputs to get a decent result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ft_preds(text_iter):\n",
    "    preds = []\n",
    "    for i in range(len(text_iter)):\n",
    "        pred = ft_model.predict(re.sub('\\\\n','',text_iter[i]))\n",
    "        if int(list(pred[0][0]).pop()) == 1:\n",
    "            preds.append(pred[1][0])\n",
    "        else:\n",
    "            preds.append(1-pred[1][0])\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recurrent Neural Network\n",
    "We trained a bespoke RNN to see if we could get strong performance. The vectorizer here is embedded in the input layer of the model. \n",
    "\n",
    "We found that a threshold of 0.80 worked well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x7fee1912d070>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rn_model = keras.models.load_model('quora_rnn')\n",
    "rn_thresh = 0.80\n",
    "rn_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT Model\n",
    "We additionally trained a BERT-architecture model, which performed very well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining our Models\n",
    "\n",
    "There are a number of methodologies for combining models in an ensemble. Here, we're going to try three different methods:\n",
    "1. Modal (Voting)\n",
    "2. Mean Probability\n",
    "3. Simple 2-Layer Network Combination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modal (Voting)\n",
    "\n",
    "Here we will take the raw predictions from each model to determine the right selection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_text</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>lr_prob</th>\n",
       "      <th>gb_prob</th>\n",
       "      <th>nb_prob</th>\n",
       "      <th>ft_prob</th>\n",
       "      <th>rn_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the most effective classroom managemen...</td>\n",
       "      <td>What is the most effective classroom managemen...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000555</td>\n",
       "      <td>0.039844</td>\n",
       "      <td>9.134136e-07</td>\n",
       "      <td>0.999542</td>\n",
       "      <td>-1.653022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Can I study abroad after 10th class from Bangl...</td>\n",
       "      <td>Can I study abroad after 10th class from Bangl...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005821</td>\n",
       "      <td>0.063862</td>\n",
       "      <td>9.495923e-03</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>-1.111974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How can I make friends as a college junior?</td>\n",
       "      <td>How can I make friends as a college junior?</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004117</td>\n",
       "      <td>0.121463</td>\n",
       "      <td>9.901345e-03</td>\n",
       "      <td>0.999745</td>\n",
       "      <td>-0.571558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How do I download free APK Minecraft: Pocket E...</td>\n",
       "      <td>How do I download free APK Minecraft: Pocket E...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000692</td>\n",
       "      <td>0.149042</td>\n",
       "      <td>1.056736e-11</td>\n",
       "      <td>1.000005</td>\n",
       "      <td>-2.614906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Like Kuvera, is \"Groww\" also a free online inv...</td>\n",
       "      <td>Like Kuvera, is \"Groww\" also a free online inv...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.083766</td>\n",
       "      <td>6.679665e-09</td>\n",
       "      <td>0.999964</td>\n",
       "      <td>-11.722013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044892</th>\n",
       "      <td>How is a video similar to ordinary graphics?</td>\n",
       "      <td>How is a video similar to ordinary graphics?</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003105</td>\n",
       "      <td>0.176345</td>\n",
       "      <td>4.799263e-03</td>\n",
       "      <td>0.999970</td>\n",
       "      <td>-0.391307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044893</th>\n",
       "      <td>How does training with a speed bag make you a ...</td>\n",
       "      <td>How does training with a speed bag make you a ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005284</td>\n",
       "      <td>0.120387</td>\n",
       "      <td>2.182861e-03</td>\n",
       "      <td>0.994148</td>\n",
       "      <td>-0.420259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044894</th>\n",
       "      <td>What marketing strategies are implemented to i...</td>\n",
       "      <td>What marketing strategies are implemented to i...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000960</td>\n",
       "      <td>0.170836</td>\n",
       "      <td>4.564579e-11</td>\n",
       "      <td>0.999723</td>\n",
       "      <td>-3.145134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044895</th>\n",
       "      <td>What are the characteristics of wireless adapt...</td>\n",
       "      <td>What are the characteristics of wireless adapt...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002340</td>\n",
       "      <td>0.150778</td>\n",
       "      <td>1.079880e-05</td>\n",
       "      <td>1.000007</td>\n",
       "      <td>-0.734787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044896</th>\n",
       "      <td>What is your experience with using fuel additi...</td>\n",
       "      <td>What is your experience with using fuel additi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001454</td>\n",
       "      <td>0.127501</td>\n",
       "      <td>1.097657e-07</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>-3.103641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1044897 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             original_text  \\\n",
       "0        What is the most effective classroom managemen...   \n",
       "1        Can I study abroad after 10th class from Bangl...   \n",
       "2              How can I make friends as a college junior?   \n",
       "3        How do I download free APK Minecraft: Pocket E...   \n",
       "4        Like Kuvera, is \"Groww\" also a free online inv...   \n",
       "...                                                    ...   \n",
       "1044892       How is a video similar to ordinary graphics?   \n",
       "1044893  How does training with a speed bag make you a ...   \n",
       "1044894  What marketing strategies are implemented to i...   \n",
       "1044895  What are the characteristics of wireless adapt...   \n",
       "1044896  What is your experience with using fuel additi...   \n",
       "\n",
       "                                                      text  label   lr_prob  \\\n",
       "0        What is the most effective classroom managemen...      0  0.000555   \n",
       "1        Can I study abroad after 10th class from Bangl...      0  0.005821   \n",
       "2              How can I make friends as a college junior?      0  0.004117   \n",
       "3        How do I download free APK Minecraft: Pocket E...      0  0.000692   \n",
       "4        Like Kuvera, is \"Groww\" also a free online inv...      0  0.000191   \n",
       "...                                                    ...    ...       ...   \n",
       "1044892       How is a video similar to ordinary graphics?      0  0.003105   \n",
       "1044893  How does training with a speed bag make you a ...      0  0.005284   \n",
       "1044894  What marketing strategies are implemented to i...      0  0.000960   \n",
       "1044895  What are the characteristics of wireless adapt...      0  0.002340   \n",
       "1044896  What is your experience with using fuel additi...      0  0.001454   \n",
       "\n",
       "          gb_prob       nb_prob   ft_prob    rn_prob  \n",
       "0        0.039844  9.134136e-07  0.999542  -1.653022  \n",
       "1        0.063862  9.495923e-03  0.999979  -1.111974  \n",
       "2        0.121463  9.901345e-03  0.999745  -0.571558  \n",
       "3        0.149042  1.056736e-11  1.000005  -2.614906  \n",
       "4        0.083766  6.679665e-09  0.999964 -11.722013  \n",
       "...           ...           ...       ...        ...  \n",
       "1044892  0.176345  4.799263e-03  0.999970  -0.391307  \n",
       "1044893  0.120387  2.182861e-03  0.994148  -0.420259  \n",
       "1044894  0.170836  4.564579e-11  0.999723  -3.145134  \n",
       "1044895  0.150778  1.079880e-05  1.000007  -0.734787  \n",
       "1044896  0.127501  1.097657e-07  0.999982  -3.103641  \n",
       "\n",
       "[1044897 rows x 8 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.DataFrame(train)\n",
    "train_df[\"lr_prob\"] = [i[1] for i in lr_model.predict_proba(lr_train)]\n",
    "train_df[\"gb_prob\"] = [i[1] for i in gb_model.predict_proba(gb_train_v)]\n",
    "train_df[\"nb_prob\"] = [i[1] for i in nb_model.predict_proba(nb_train)]\n",
    "train_df[\"ft_prob\"] = get_ft_preds(train.text)\n",
    "train_df[\"rn_prob\"] = rn_model.predict(train.text)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_text</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>lr_prob</th>\n",
       "      <th>gb_prob</th>\n",
       "      <th>nb_prob</th>\n",
       "      <th>ft_prob</th>\n",
       "      <th>rn_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Does my BDS degree from India count if I want ...</td>\n",
       "      <td>Does my BDS degree from India count if I want ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.224557</td>\n",
       "      <td>9.497170e-09</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>-3.479209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Is there such a thing as an average face?</td>\n",
       "      <td>Is there such a thing as an average face?</td>\n",
       "      <td>0</td>\n",
       "      <td>0.035331</td>\n",
       "      <td>0.201973</td>\n",
       "      <td>4.246348e-01</td>\n",
       "      <td>0.007789</td>\n",
       "      <td>0.251670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Is Munich Volkshochschule a good choice to lea...</td>\n",
       "      <td>Is Munich Volkshochschule a good choice to lea...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.021947</td>\n",
       "      <td>0.153941</td>\n",
       "      <td>1.355363e-03</td>\n",
       "      <td>0.004811</td>\n",
       "      <td>0.076729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is The relationship between Texas and its...</td>\n",
       "      <td>What is The relationship between Texas and its...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007457</td>\n",
       "      <td>0.276170</td>\n",
       "      <td>6.619439e-01</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>-0.625006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Will the current mining equipment work with se...</td>\n",
       "      <td>Will the current mining equipment work with se...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005579</td>\n",
       "      <td>0.100898</td>\n",
       "      <td>1.270251e-05</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>-1.466719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130607</th>\n",
       "      <td>What's the best way to teach your daughter to ...</td>\n",
       "      <td>What's the best way to teach your daughter to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.041944</td>\n",
       "      <td>0.180011</td>\n",
       "      <td>4.178595e-02</td>\n",
       "      <td>0.020944</td>\n",
       "      <td>0.561008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130608</th>\n",
       "      <td>What are similarities and differences between ...</td>\n",
       "      <td>What are similarities and differences between ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004699</td>\n",
       "      <td>0.110094</td>\n",
       "      <td>9.151326e-03</td>\n",
       "      <td>0.001823</td>\n",
       "      <td>-1.285976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130609</th>\n",
       "      <td>What is the best shoe cleaning product for tri...</td>\n",
       "      <td>What is the best shoe cleaning product for tri...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003072</td>\n",
       "      <td>0.192046</td>\n",
       "      <td>6.060790e-03</td>\n",
       "      <td>0.000542</td>\n",
       "      <td>0.658570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130610</th>\n",
       "      <td>Can I get a private medical college with 320 m...</td>\n",
       "      <td>Can I get a private medical college with 320 m...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001279</td>\n",
       "      <td>0.049469</td>\n",
       "      <td>5.716538e-07</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>-10.727527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130611</th>\n",
       "      <td>What are some key differences between America ...</td>\n",
       "      <td>What are some key differences between America ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004609</td>\n",
       "      <td>0.248608</td>\n",
       "      <td>1.336022e-01</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>-0.806871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130612 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            original_text  \\\n",
       "0       Does my BDS degree from India count if I want ...   \n",
       "1               Is there such a thing as an average face?   \n",
       "2       Is Munich Volkshochschule a good choice to lea...   \n",
       "3       What is The relationship between Texas and its...   \n",
       "4       Will the current mining equipment work with se...   \n",
       "...                                                   ...   \n",
       "130607  What's the best way to teach your daughter to ...   \n",
       "130608  What are similarities and differences between ...   \n",
       "130609  What is the best shoe cleaning product for tri...   \n",
       "130610  Can I get a private medical college with 320 m...   \n",
       "130611  What are some key differences between America ...   \n",
       "\n",
       "                                                     text  label   lr_prob  \\\n",
       "0       Does my BDS degree from India count if I want ...      0  0.000071   \n",
       "1               Is there such a thing as an average face?      0  0.035331   \n",
       "2       Is Munich Volkshochschule a good choice to lea...      0  0.021947   \n",
       "3       What is The relationship between Texas and its...      0  0.007457   \n",
       "4       Will the current mining equipment work with se...      0  0.005579   \n",
       "...                                                   ...    ...       ...   \n",
       "130607  What's the best way to teach your daughter to ...      0  0.041944   \n",
       "130608  What are similarities and differences between ...      0  0.004699   \n",
       "130609  What is the best shoe cleaning product for tri...      0  0.003072   \n",
       "130610  Can I get a private medical college with 320 m...      0  0.001279   \n",
       "130611  What are some key differences between America ...      0  0.004609   \n",
       "\n",
       "         gb_prob       nb_prob   ft_prob    rn_prob  \n",
       "0       0.224557  9.497170e-09  0.000098  -3.479209  \n",
       "1       0.201973  4.246348e-01  0.007789   0.251670  \n",
       "2       0.153941  1.355363e-03  0.004811   0.076729  \n",
       "3       0.276170  6.619439e-01  0.001019  -0.625006  \n",
       "4       0.100898  1.270251e-05 -0.000007  -1.466719  \n",
       "...          ...           ...       ...        ...  \n",
       "130607  0.180011  4.178595e-02  0.020944   0.561008  \n",
       "130608  0.110094  9.151326e-03  0.001823  -1.285976  \n",
       "130609  0.192046  6.060790e-03  0.000542   0.658570  \n",
       "130610  0.049469  5.716538e-07  0.000184 -10.727527  \n",
       "130611  0.248608  1.336022e-01  0.000316  -0.806871  \n",
       "\n",
       "[130612 rows x 8 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.DataFrame(test)\n",
    "test_df[\"lr_prob\"] = [i[1] for i in lr_model.predict_proba(lr_test)]\n",
    "test_df[\"gb_prob\"] = [i[1] for i in gb_model.predict_proba(gb_test_v)]\n",
    "test_df[\"nb_prob\"] = [i[1] for i in nb_model.predict_proba(nb_test)]\n",
    "test_df[\"ft_prob\"] = get_ft_preds(test.text)\n",
    "test_df[\"rn_prob\"] = rn_model.predict(test.text)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_text</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>lr_prob</th>\n",
       "      <th>gb_prob</th>\n",
       "      <th>nb_prob</th>\n",
       "      <th>ft_prob</th>\n",
       "      <th>rn_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Where can I find best romantic shayaris?</td>\n",
       "      <td>Where can I find best romantic shayaris?</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003461</td>\n",
       "      <td>0.066572</td>\n",
       "      <td>1.537171e-03</td>\n",
       "      <td>-1.192093e-07</td>\n",
       "      <td>-0.226986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When we check the UPSC rank list; many of the ...</td>\n",
       "      <td>When we check the UPSC rank list; many of the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003836</td>\n",
       "      <td>0.127764</td>\n",
       "      <td>8.641639e-07</td>\n",
       "      <td>1.839083e-02</td>\n",
       "      <td>-0.060640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Is there is any web site to create search engi...</td>\n",
       "      <td>Is there is any web site to create search engi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003249</td>\n",
       "      <td>0.115049</td>\n",
       "      <td>1.516661e-04</td>\n",
       "      <td>2.480149e-04</td>\n",
       "      <td>-1.356835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How can you earn $50 just clicking ads?</td>\n",
       "      <td>How can you earn $50 just clicking ads?</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002562</td>\n",
       "      <td>0.184455</td>\n",
       "      <td>1.987959e-02</td>\n",
       "      <td>-8.940697e-06</td>\n",
       "      <td>-0.865699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which 3 branches of engineering have the most ...</td>\n",
       "      <td>Which 3 branches of engineering have the most ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.051391</td>\n",
       "      <td>3.259093e-06</td>\n",
       "      <td>4.172325e-06</td>\n",
       "      <td>-2.535836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130608</th>\n",
       "      <td>How can the ViewSonic PA503S 3600 lumens SVGA ...</td>\n",
       "      <td>How can the ViewSonic PA503S 3600 lumens SVGA ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001746</td>\n",
       "      <td>0.118619</td>\n",
       "      <td>6.697781e-13</td>\n",
       "      <td>1.001358e-05</td>\n",
       "      <td>-0.661709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130609</th>\n",
       "      <td>What are the biggest myths about Adolf Hitler?</td>\n",
       "      <td>What are the biggest myths about Adolf Hitler?</td>\n",
       "      <td>0</td>\n",
       "      <td>0.045431</td>\n",
       "      <td>0.534086</td>\n",
       "      <td>7.244850e-01</td>\n",
       "      <td>2.488196e-03</td>\n",
       "      <td>0.663470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130610</th>\n",
       "      <td>What song played in the movie of the gifted wh...</td>\n",
       "      <td>What song played in the movie of the gifted wh...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008959</td>\n",
       "      <td>0.131536</td>\n",
       "      <td>9.977263e-01</td>\n",
       "      <td>1.437485e-03</td>\n",
       "      <td>-0.627733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130611</th>\n",
       "      <td>What do Socrates, Thomas Kuhn and Karl Popper ...</td>\n",
       "      <td>What do Socrates, Thomas Kuhn and Karl Popper ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008071</td>\n",
       "      <td>0.233031</td>\n",
       "      <td>4.444433e-01</td>\n",
       "      <td>4.540682e-04</td>\n",
       "      <td>0.040162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130612</th>\n",
       "      <td>I feel something missing in my relationship. I...</td>\n",
       "      <td>I feel something missing in my relationship. I...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>0.175806</td>\n",
       "      <td>1.254916e-01</td>\n",
       "      <td>2.029568e-02</td>\n",
       "      <td>-1.959324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130613 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            original_text  \\\n",
       "0                Where can I find best romantic shayaris?   \n",
       "1       When we check the UPSC rank list; many of the ...   \n",
       "2       Is there is any web site to create search engi...   \n",
       "3                 How can you earn $50 just clicking ads?   \n",
       "4       Which 3 branches of engineering have the most ...   \n",
       "...                                                   ...   \n",
       "130608  How can the ViewSonic PA503S 3600 lumens SVGA ...   \n",
       "130609     What are the biggest myths about Adolf Hitler?   \n",
       "130610  What song played in the movie of the gifted wh...   \n",
       "130611  What do Socrates, Thomas Kuhn and Karl Popper ...   \n",
       "130612  I feel something missing in my relationship. I...   \n",
       "\n",
       "                                                     text  label   lr_prob  \\\n",
       "0                Where can I find best romantic shayaris?      1  0.003461   \n",
       "1       When we check the UPSC rank list; many of the ...      0  0.003836   \n",
       "2       Is there is any web site to create search engi...      0  0.003249   \n",
       "3                 How can you earn $50 just clicking ads?      0  0.002562   \n",
       "4       Which 3 branches of engineering have the most ...      0  0.000199   \n",
       "...                                                   ...    ...       ...   \n",
       "130608  How can the ViewSonic PA503S 3600 lumens SVGA ...      0  0.001746   \n",
       "130609     What are the biggest myths about Adolf Hitler?      0  0.045431   \n",
       "130610  What song played in the movie of the gifted wh...      0  0.008959   \n",
       "130611  What do Socrates, Thomas Kuhn and Karl Popper ...      0  0.008071   \n",
       "130612  I feel something missing in my relationship. I...      0  0.000256   \n",
       "\n",
       "         gb_prob       nb_prob       ft_prob   rn_prob  \n",
       "0       0.066572  1.537171e-03 -1.192093e-07 -0.226986  \n",
       "1       0.127764  8.641639e-07  1.839083e-02 -0.060640  \n",
       "2       0.115049  1.516661e-04  2.480149e-04 -1.356835  \n",
       "3       0.184455  1.987959e-02 -8.940697e-06 -0.865699  \n",
       "4       0.051391  3.259093e-06  4.172325e-06 -2.535836  \n",
       "...          ...           ...           ...       ...  \n",
       "130608  0.118619  6.697781e-13  1.001358e-05 -0.661709  \n",
       "130609  0.534086  7.244850e-01  2.488196e-03  0.663470  \n",
       "130610  0.131536  9.977263e-01  1.437485e-03 -0.627733  \n",
       "130611  0.233031  4.444433e-01  4.540682e-04  0.040162  \n",
       "130612  0.175806  1.254916e-01  2.029568e-02 -1.959324  \n",
       "\n",
       "[130613 rows x 8 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_df = pd.DataFrame(dev)\n",
    "dev_df[\"lr_prob\"] = [i[1] for i in lr_model.predict_proba(lr_dev)]\n",
    "dev_df[\"gb_prob\"] = [i[1] for i in gb_model.predict_proba(gb_dev_v)]\n",
    "dev_df[\"nb_prob\"] = [i[1] for i in nb_model.predict_proba(nb_dev)]\n",
    "dev_df[\"ft_prob\"] = get_ft_preds(dev.text)\n",
    "dev_df[\"rn_prob\"] = rn_model.predict(dev.text)\n",
    "dev_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can \"vote\" among the methods to determine the right class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_text</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>lr_prob</th>\n",
       "      <th>gb_prob</th>\n",
       "      <th>nb_prob</th>\n",
       "      <th>ft_prob</th>\n",
       "      <th>rn_prob</th>\n",
       "      <th>modal_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Where can I find best romantic shayaris?</td>\n",
       "      <td>Where can I find best romantic shayaris?</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003461</td>\n",
       "      <td>0.066572</td>\n",
       "      <td>1.537171e-03</td>\n",
       "      <td>-1.192093e-07</td>\n",
       "      <td>-0.226986</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When we check the UPSC rank list; many of the ...</td>\n",
       "      <td>When we check the UPSC rank list; many of the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003836</td>\n",
       "      <td>0.127764</td>\n",
       "      <td>8.641639e-07</td>\n",
       "      <td>1.839083e-02</td>\n",
       "      <td>-0.060640</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Is there is any web site to create search engi...</td>\n",
       "      <td>Is there is any web site to create search engi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003249</td>\n",
       "      <td>0.115049</td>\n",
       "      <td>1.516661e-04</td>\n",
       "      <td>2.480149e-04</td>\n",
       "      <td>-1.356835</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How can you earn $50 just clicking ads?</td>\n",
       "      <td>How can you earn $50 just clicking ads?</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002562</td>\n",
       "      <td>0.184455</td>\n",
       "      <td>1.987959e-02</td>\n",
       "      <td>-8.940697e-06</td>\n",
       "      <td>-0.865699</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which 3 branches of engineering have the most ...</td>\n",
       "      <td>Which 3 branches of engineering have the most ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.051391</td>\n",
       "      <td>3.259093e-06</td>\n",
       "      <td>4.172325e-06</td>\n",
       "      <td>-2.535836</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130608</th>\n",
       "      <td>How can the ViewSonic PA503S 3600 lumens SVGA ...</td>\n",
       "      <td>How can the ViewSonic PA503S 3600 lumens SVGA ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001746</td>\n",
       "      <td>0.118619</td>\n",
       "      <td>6.697781e-13</td>\n",
       "      <td>1.001358e-05</td>\n",
       "      <td>-0.661709</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130609</th>\n",
       "      <td>What are the biggest myths about Adolf Hitler?</td>\n",
       "      <td>What are the biggest myths about Adolf Hitler?</td>\n",
       "      <td>0</td>\n",
       "      <td>0.045431</td>\n",
       "      <td>0.534086</td>\n",
       "      <td>7.244850e-01</td>\n",
       "      <td>2.488196e-03</td>\n",
       "      <td>0.663470</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130610</th>\n",
       "      <td>What song played in the movie of the gifted wh...</td>\n",
       "      <td>What song played in the movie of the gifted wh...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008959</td>\n",
       "      <td>0.131536</td>\n",
       "      <td>9.977263e-01</td>\n",
       "      <td>1.437485e-03</td>\n",
       "      <td>-0.627733</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130611</th>\n",
       "      <td>What do Socrates, Thomas Kuhn and Karl Popper ...</td>\n",
       "      <td>What do Socrates, Thomas Kuhn and Karl Popper ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008071</td>\n",
       "      <td>0.233031</td>\n",
       "      <td>4.444433e-01</td>\n",
       "      <td>4.540682e-04</td>\n",
       "      <td>0.040162</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130612</th>\n",
       "      <td>I feel something missing in my relationship. I...</td>\n",
       "      <td>I feel something missing in my relationship. I...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>0.175806</td>\n",
       "      <td>1.254916e-01</td>\n",
       "      <td>2.029568e-02</td>\n",
       "      <td>-1.959324</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130613 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            original_text  \\\n",
       "0                Where can I find best romantic shayaris?   \n",
       "1       When we check the UPSC rank list; many of the ...   \n",
       "2       Is there is any web site to create search engi...   \n",
       "3                 How can you earn $50 just clicking ads?   \n",
       "4       Which 3 branches of engineering have the most ...   \n",
       "...                                                   ...   \n",
       "130608  How can the ViewSonic PA503S 3600 lumens SVGA ...   \n",
       "130609     What are the biggest myths about Adolf Hitler?   \n",
       "130610  What song played in the movie of the gifted wh...   \n",
       "130611  What do Socrates, Thomas Kuhn and Karl Popper ...   \n",
       "130612  I feel something missing in my relationship. I...   \n",
       "\n",
       "                                                     text  label   lr_prob  \\\n",
       "0                Where can I find best romantic shayaris?      1  0.003461   \n",
       "1       When we check the UPSC rank list; many of the ...      0  0.003836   \n",
       "2       Is there is any web site to create search engi...      0  0.003249   \n",
       "3                 How can you earn $50 just clicking ads?      0  0.002562   \n",
       "4       Which 3 branches of engineering have the most ...      0  0.000199   \n",
       "...                                                   ...    ...       ...   \n",
       "130608  How can the ViewSonic PA503S 3600 lumens SVGA ...      0  0.001746   \n",
       "130609     What are the biggest myths about Adolf Hitler?      0  0.045431   \n",
       "130610  What song played in the movie of the gifted wh...      0  0.008959   \n",
       "130611  What do Socrates, Thomas Kuhn and Karl Popper ...      0  0.008071   \n",
       "130612  I feel something missing in my relationship. I...      0  0.000256   \n",
       "\n",
       "         gb_prob       nb_prob       ft_prob   rn_prob  modal_pred  \n",
       "0       0.066572  1.537171e-03 -1.192093e-07 -0.226986           0  \n",
       "1       0.127764  8.641639e-07  1.839083e-02 -0.060640           0  \n",
       "2       0.115049  1.516661e-04  2.480149e-04 -1.356835           0  \n",
       "3       0.184455  1.987959e-02 -8.940697e-06 -0.865699           0  \n",
       "4       0.051391  3.259093e-06  4.172325e-06 -2.535836           0  \n",
       "...          ...           ...           ...       ...         ...  \n",
       "130608  0.118619  6.697781e-13  1.001358e-05 -0.661709           0  \n",
       "130609  0.534086  7.244850e-01  2.488196e-03  0.663470           0  \n",
       "130610  0.131536  9.977263e-01  1.437485e-03 -0.627733           0  \n",
       "130611  0.233031  4.444433e-01  4.540682e-04  0.040162           0  \n",
       "130612  0.175806  1.254916e-01  2.029568e-02 -1.959324           0  \n",
       "\n",
       "[130613 rows x 9 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def modal_prediction(row):\n",
    "    votes = 0\n",
    "    if row.lr_prob >= lr_thresh:\n",
    "        votes +=  1\n",
    "    else:\n",
    "        votes += -1\n",
    "    if row.gb_prob >= gb_thresh:\n",
    "        votes +=  1\n",
    "    else:\n",
    "        votes += -1\n",
    "    if row.nb_prob >= nb_thresh:\n",
    "        votes +=  1\n",
    "    else:\n",
    "        votes += -1\n",
    "    if row.ft_prob >= ft_thresh:\n",
    "        votes +=  1\n",
    "    else:\n",
    "        votes += -1\n",
    "    if row.rn_prob >= rn_thresh:\n",
    "        votes +=  1\n",
    "    else:\n",
    "        votes += -1\n",
    "    \n",
    "    if votes > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "dev_df[\"modal_pred\"] = dev_df.apply(modal_prediction, axis=1)\n",
    "dev_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97    122465\n",
      "           1       0.57      0.68      0.62      8148\n",
      "\n",
      "    accuracy                           0.95    130613\n",
      "   macro avg       0.77      0.82      0.80    130613\n",
      "weighted avg       0.95      0.95      0.95    130613\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(dev_df.label, dev_df.modal_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that this returns an F1 score of ~62%, which is equal to what we get on Logistic Regression. Let's try another method and see if we get better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Probability\n",
    "\n",
    "If we average the probabilities of all methods, we may get a more accurate prediction. We will need to standardize the RNN-probabilities though, since it currently outputs values above 1 and below 0. We can do this by simply setting a floor and cieling on this field. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_text</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>lr_prob</th>\n",
       "      <th>gb_prob</th>\n",
       "      <th>nb_prob</th>\n",
       "      <th>ft_prob</th>\n",
       "      <th>rn_prob</th>\n",
       "      <th>modal_pred</th>\n",
       "      <th>mean_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Where can I find best romantic shayaris?</td>\n",
       "      <td>Where can I find best romantic shayaris?</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003461</td>\n",
       "      <td>0.066572</td>\n",
       "      <td>1.537171e-03</td>\n",
       "      <td>-1.192093e-07</td>\n",
       "      <td>-0.226986</td>\n",
       "      <td>0</td>\n",
       "      <td>0.071570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When we check the UPSC rank list; many of the ...</td>\n",
       "      <td>When we check the UPSC rank list; many of the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003836</td>\n",
       "      <td>0.127764</td>\n",
       "      <td>8.641639e-07</td>\n",
       "      <td>1.839083e-02</td>\n",
       "      <td>-0.060640</td>\n",
       "      <td>0</td>\n",
       "      <td>0.149992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Is there is any web site to create search engi...</td>\n",
       "      <td>Is there is any web site to create search engi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003249</td>\n",
       "      <td>0.115049</td>\n",
       "      <td>1.516661e-04</td>\n",
       "      <td>2.480149e-04</td>\n",
       "      <td>-1.356835</td>\n",
       "      <td>0</td>\n",
       "      <td>0.118697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How can you earn $50 just clicking ads?</td>\n",
       "      <td>How can you earn $50 just clicking ads?</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002562</td>\n",
       "      <td>0.184455</td>\n",
       "      <td>1.987959e-02</td>\n",
       "      <td>-8.940697e-06</td>\n",
       "      <td>-0.865699</td>\n",
       "      <td>0</td>\n",
       "      <td>0.206888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which 3 branches of engineering have the most ...</td>\n",
       "      <td>Which 3 branches of engineering have the most ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.051391</td>\n",
       "      <td>3.259093e-06</td>\n",
       "      <td>4.172325e-06</td>\n",
       "      <td>-2.535836</td>\n",
       "      <td>0</td>\n",
       "      <td>0.051597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130608</th>\n",
       "      <td>How can the ViewSonic PA503S 3600 lumens SVGA ...</td>\n",
       "      <td>How can the ViewSonic PA503S 3600 lumens SVGA ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001746</td>\n",
       "      <td>0.118619</td>\n",
       "      <td>6.697781e-13</td>\n",
       "      <td>1.001358e-05</td>\n",
       "      <td>-0.661709</td>\n",
       "      <td>0</td>\n",
       "      <td>0.120375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130609</th>\n",
       "      <td>What are the biggest myths about Adolf Hitler?</td>\n",
       "      <td>What are the biggest myths about Adolf Hitler?</td>\n",
       "      <td>0</td>\n",
       "      <td>0.045431</td>\n",
       "      <td>0.534086</td>\n",
       "      <td>7.244850e-01</td>\n",
       "      <td>2.488196e-03</td>\n",
       "      <td>0.663470</td>\n",
       "      <td>0</td>\n",
       "      <td>1.969961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130610</th>\n",
       "      <td>What song played in the movie of the gifted wh...</td>\n",
       "      <td>What song played in the movie of the gifted wh...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008959</td>\n",
       "      <td>0.131536</td>\n",
       "      <td>9.977263e-01</td>\n",
       "      <td>1.437485e-03</td>\n",
       "      <td>-0.627733</td>\n",
       "      <td>0</td>\n",
       "      <td>1.139659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130611</th>\n",
       "      <td>What do Socrates, Thomas Kuhn and Karl Popper ...</td>\n",
       "      <td>What do Socrates, Thomas Kuhn and Karl Popper ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008071</td>\n",
       "      <td>0.233031</td>\n",
       "      <td>4.444433e-01</td>\n",
       "      <td>4.540682e-04</td>\n",
       "      <td>0.040162</td>\n",
       "      <td>0</td>\n",
       "      <td>0.726161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130612</th>\n",
       "      <td>I feel something missing in my relationship. I...</td>\n",
       "      <td>I feel something missing in my relationship. I...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>0.175806</td>\n",
       "      <td>1.254916e-01</td>\n",
       "      <td>2.029568e-02</td>\n",
       "      <td>-1.959324</td>\n",
       "      <td>0</td>\n",
       "      <td>0.321849</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130613 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            original_text  \\\n",
       "0                Where can I find best romantic shayaris?   \n",
       "1       When we check the UPSC rank list; many of the ...   \n",
       "2       Is there is any web site to create search engi...   \n",
       "3                 How can you earn $50 just clicking ads?   \n",
       "4       Which 3 branches of engineering have the most ...   \n",
       "...                                                   ...   \n",
       "130608  How can the ViewSonic PA503S 3600 lumens SVGA ...   \n",
       "130609     What are the biggest myths about Adolf Hitler?   \n",
       "130610  What song played in the movie of the gifted wh...   \n",
       "130611  What do Socrates, Thomas Kuhn and Karl Popper ...   \n",
       "130612  I feel something missing in my relationship. I...   \n",
       "\n",
       "                                                     text  label   lr_prob  \\\n",
       "0                Where can I find best romantic shayaris?      1  0.003461   \n",
       "1       When we check the UPSC rank list; many of the ...      0  0.003836   \n",
       "2       Is there is any web site to create search engi...      0  0.003249   \n",
       "3                 How can you earn $50 just clicking ads?      0  0.002562   \n",
       "4       Which 3 branches of engineering have the most ...      0  0.000199   \n",
       "...                                                   ...    ...       ...   \n",
       "130608  How can the ViewSonic PA503S 3600 lumens SVGA ...      0  0.001746   \n",
       "130609     What are the biggest myths about Adolf Hitler?      0  0.045431   \n",
       "130610  What song played in the movie of the gifted wh...      0  0.008959   \n",
       "130611  What do Socrates, Thomas Kuhn and Karl Popper ...      0  0.008071   \n",
       "130612  I feel something missing in my relationship. I...      0  0.000256   \n",
       "\n",
       "         gb_prob       nb_prob       ft_prob   rn_prob  modal_pred  mean_prob  \n",
       "0       0.066572  1.537171e-03 -1.192093e-07 -0.226986           0   0.071570  \n",
       "1       0.127764  8.641639e-07  1.839083e-02 -0.060640           0   0.149992  \n",
       "2       0.115049  1.516661e-04  2.480149e-04 -1.356835           0   0.118697  \n",
       "3       0.184455  1.987959e-02 -8.940697e-06 -0.865699           0   0.206888  \n",
       "4       0.051391  3.259093e-06  4.172325e-06 -2.535836           0   0.051597  \n",
       "...          ...           ...           ...       ...         ...        ...  \n",
       "130608  0.118619  6.697781e-13  1.001358e-05 -0.661709           0   0.120375  \n",
       "130609  0.534086  7.244850e-01  2.488196e-03  0.663470           0   1.969961  \n",
       "130610  0.131536  9.977263e-01  1.437485e-03 -0.627733           0   1.139659  \n",
       "130611  0.233031  4.444433e-01  4.540682e-04  0.040162           0   0.726161  \n",
       "130612  0.175806  1.254916e-01  2.029568e-02 -1.959324           0   0.321849  \n",
       "\n",
       "[130613 rows x 10 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mean_proba(row):\n",
    "    return sum([\n",
    "        row.lr_prob,\n",
    "        row.gb_prob,\n",
    "        row.nb_prob,\n",
    "        row.ft_prob,\n",
    "        max(min(row.rn_prob,1),0)\n",
    "    ])\n",
    "\n",
    "dev_df[\"mean_prob\"] = dev_df.apply(mean_proba, axis=1)\n",
    "\n",
    "dev_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply our standard grid search to this probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>f1Score</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.120011</td>\n",
       "      <td>0.085152</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.063836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.129459</td>\n",
       "      <td>0.162258</td>\n",
       "      <td>0.998527</td>\n",
       "      <td>0.069217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.145699</td>\n",
       "      <td>0.271497</td>\n",
       "      <td>0.995827</td>\n",
       "      <td>0.078600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.166679</td>\n",
       "      <td>0.380284</td>\n",
       "      <td>0.993495</td>\n",
       "      <td>0.090970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.195718</td>\n",
       "      <td>0.492952</td>\n",
       "      <td>0.988954</td>\n",
       "      <td>0.108606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.217573</td>\n",
       "      <td>0.557601</td>\n",
       "      <td>0.986009</td>\n",
       "      <td>0.122278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.235009</td>\n",
       "      <td>0.600798</td>\n",
       "      <td>0.982941</td>\n",
       "      <td>0.133459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.250695</td>\n",
       "      <td>0.634638</td>\n",
       "      <td>0.979750</td>\n",
       "      <td>0.143737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.265234</td>\n",
       "      <td>0.662384</td>\n",
       "      <td>0.976804</td>\n",
       "      <td>0.153450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.278595</td>\n",
       "      <td>0.685253</td>\n",
       "      <td>0.974227</td>\n",
       "      <td>0.162537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.291047</td>\n",
       "      <td>0.704815</td>\n",
       "      <td>0.971281</td>\n",
       "      <td>0.171169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.302661</td>\n",
       "      <td>0.721498</td>\n",
       "      <td>0.968827</td>\n",
       "      <td>0.179344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.313200</td>\n",
       "      <td>0.735777</td>\n",
       "      <td>0.965758</td>\n",
       "      <td>0.186908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.323906</td>\n",
       "      <td>0.749259</td>\n",
       "      <td>0.962813</td>\n",
       "      <td>0.194704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.335531</td>\n",
       "      <td>0.763079</td>\n",
       "      <td>0.958886</td>\n",
       "      <td>0.203342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.346350</td>\n",
       "      <td>0.775084</td>\n",
       "      <td>0.955204</td>\n",
       "      <td>0.211523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.357194</td>\n",
       "      <td>0.786246</td>\n",
       "      <td>0.952013</td>\n",
       "      <td>0.219838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.368442</td>\n",
       "      <td>0.796950</td>\n",
       "      <td>0.949435</td>\n",
       "      <td>0.228571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.379348</td>\n",
       "      <td>0.806819</td>\n",
       "      <td>0.946367</td>\n",
       "      <td>0.237218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    threshold   f1Score  accuracy    recall  precision\n",
       "0        0.05  0.120011  0.085152  1.000000   0.063836\n",
       "1        0.10  0.129459  0.162258  0.998527   0.069217\n",
       "2        0.15  0.145699  0.271497  0.995827   0.078600\n",
       "3        0.20  0.166679  0.380284  0.993495   0.090970\n",
       "4        0.25  0.195718  0.492952  0.988954   0.108606\n",
       "5        0.30  0.217573  0.557601  0.986009   0.122278\n",
       "6        0.35  0.235009  0.600798  0.982941   0.133459\n",
       "7        0.40  0.250695  0.634638  0.979750   0.143737\n",
       "8        0.45  0.265234  0.662384  0.976804   0.153450\n",
       "9        0.50  0.278595  0.685253  0.974227   0.162537\n",
       "10       0.55  0.291047  0.704815  0.971281   0.171169\n",
       "11       0.60  0.302661  0.721498  0.968827   0.179344\n",
       "12       0.65  0.313200  0.735777  0.965758   0.186908\n",
       "13       0.70  0.323906  0.749259  0.962813   0.194704\n",
       "14       0.75  0.335531  0.763079  0.958886   0.203342\n",
       "15       0.80  0.346350  0.775084  0.955204   0.211523\n",
       "16       0.85  0.357194  0.786246  0.952013   0.219838\n",
       "17       0.90  0.368442  0.796950  0.949435   0.228571\n",
       "18       0.95  0.379348  0.806819  0.946367   0.237218"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def frange(start, stop, step):\n",
    "  i = start\n",
    "  while i < stop:\n",
    "    yield i\n",
    "    i += step\n",
    "\n",
    "columnNames = ['threshold', 'f1Score', 'accuracy', 'recall', 'precision']\n",
    "thresholdDF = pd.DataFrame(columns=columnNames)\n",
    "\n",
    "for i in frange(0.05,1,0.05):\n",
    "    pred2 = np.where(dev_df['mean_prob'] > i, 1, 0)\n",
    "    f1Score = f1_score(dev_df.label, pred2)\n",
    "    accuracy = accuracy_score(dev_df.label, pred2)\n",
    "    recall = recall_score(dev_df.label, pred2)\n",
    "    precision = precision_score(dev_df.label, pred2)\n",
    "    thresholdDF = thresholdDF.append({'threshold': i, 'f1Score': f1Score, \n",
    "                                      'accuracy':accuracy, 'recall':recall, \n",
    "                                      'precision':precision}, \n",
    "                                      ignore_index=True)\n",
    "\n",
    "thresholdDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This isn't very good, and it also overfits to dev! We should move on to a different method. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, 1)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(tf.keras.layers.InputLayer(5))\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='softmax'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
